import requests
import json
import pandas as pd
import pyodbc
import logging
import time
import os

# Setup logging
logging.basicConfig(level=logging.INFO)

# NVD API base URL
NVD_API_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"

# Function to fetch data from NVD API
def fetch_data_from_nvd(start_index):
    params = {
        'resultsPerPage': 2000,
        'startIndex': start_index
    }
    response = requests.get(NVD_API_URL, params=params)
    response.raise_for_status()
    return response.json()

# Function to parse NVD JSON data into a DataFrame
def parse_nvd_data(json_data):
    records = []
    for item in json_data['vulnerabilities']:
        cve_data = item['cve']
        cve_id = cve_data['id']
        source_identifier = cve_data['sourceIdentifier']
        published_date = cve_data['published']
        last_modified_date = cve_data['lastModified']
        vuln_status = cve_data['vulnStatus']
        descriptions = cve_data['descriptions']
        
        # Use the first description (English) if available
        description = next((desc['value'] for desc in descriptions if desc['lang'] == 'en'), '')

        # Extract metrics (if available)
        cvss_v2_metrics = cve_data.get('metrics', {}).get('cvssMetricV2', [])
        cvss_v3_metrics = cve_data.get('metrics', {}).get('cvssMetricV3', [])
        cvss_v31_metrics = cve_data.get('metrics', {}).get('cvssMetricV31', [])
        
        # Initialize variables for CVSSv2, CVSSv3, and CVSSv3.1 metrics
        cvss_v2 = cvss_v2_metrics[0]['cvssData'] if cvss_v2_metrics else None
        cvss_v3 = cvss_v3_metrics[0]['cvssData'] if cvss_v3_metrics else None
        cvss_v31 = cvss_v31_metrics[0]['cvssData'] if cvss_v31_metrics else None

        base_score = cvss_v2['baseScore'] if cvss_v2 else None
        vector_string = cvss_v2['vectorString'] if cvss_v2 else None
        access_vector = cvss_v2['accessVector'] if cvss_v2 else None
        access_complexity = cvss_v2['accessComplexity'] if cvss_v2 else None
        authentication = cvss_v2['authentication'] if cvss_v2 else None
        confidentiality_impact = cvss_v2['confidentialityImpact'] if cvss_v2 else None
        integrity_impact = cvss_v2['integrityImpact'] if cvss_v2 else None
        availability_impact = cvss_v2['availabilityImpact'] if cvss_v2 else None
        exploitability_score = cvss_v2_metrics[0]['exploitabilityScore'] if cvss_v2_metrics else None
        impact_score = cvss_v2_metrics[0]['impactScore'] if cvss_v2_metrics else None
        
        cvss_v3_base_score = cvss_v3['baseScore'] if cvss_v3 else None
        cvss_v3_vector_string = cvss_v3['vectorString'] if cvss_v3 else None
        cvss_v3_exploitability_score = cvss_v3_metrics[0]['exploitabilityScore'] if cvss_v3_metrics else None
        cvss_v3_impact_score = cvss_v3_metrics[0]['impactScore'] if cvss_v3_metrics else None
        
        cvss_v31_base_score = cvss_v31['baseScore'] if cvss_v31 else None
        cvss_v31_vector_string = cvss_v31['vectorString'] if cvss_v31 else None
        cvss_v31_exploitability_score = cvss_v31_metrics[0]['exploitabilityScore'] if cvss_v31_metrics else None
        cvss_v31_impact_score = cvss_v31_metrics[0]['impactScore'] if cvss_v31_metrics else None

        # Append the parsed data to the records list
        records.append({
            'cve_id': cve_id,
            'source_identifier': source_identifier,
            'published_date': published_date,
            'last_modified_date': last_modified_date,
            'vuln_status': vuln_status,
            'description': description,
            'base_score': base_score,
            'vector_string': vector_string,
            'access_vector': access_vector,
            'access_complexity': access_complexity,
            'authentication': authentication,
            'confidentiality_impact': confidentiality_impact,
            'integrity_impact': integrity_impact,
            'availability_impact': availability_impact,
            'exploitability_score': exploitability_score,
            'impact_score': impact_score,
            'cvss_v3_base_score': cvss_v3_base_score,
            'cvss_v3_vector_string': cvss_v3_vector_string,
            'cvss_v3_exploitability_score': cvss_v3_exploitability_score,
            'cvss_v3_impact_score': cvss_v3_impact_score,
            'cvss_v31_base_score': cvss_v31_base_score,
            'cvss_v31_vector_string': cvss_v31_vector_string,
            'cvss_v31_exploitability_score': cvss_v31_exploitability_score,
            'cvss_v31_impact_score': cvss_v31_impact_score
        })

    return pd.DataFrame(records)

# Function to insert data into SQL table with retry logic
def insert_data_to_sql(df, table_name, conn):
    cursor = conn.cursor()
    batch_size = 500
    for start in range(0, len(df), batch_size):
        end = start + batch_size
        batch_df = df[start:end]
        for index, row in batch_df.iterrows():
            retries = 3
            for attempt in range(retries):
                try:
                    cursor.execute(f'''
                    INSERT INTO {table_name} (
                        cve_id, source_identifier, published_date, last_modified_date, vuln_status, description, 
                        base_score, vector_string, access_vector, access_complexity, authentication, 
                        confidentiality_impact, integrity_impact, availability_impact, exploitability_score, impact_score,
                        cvss_v3_base_score, cvss_v3_vector_string, cvss_v3_exploitability_score, cvss_v3_impact_score,
                        cvss_v31_base_score, cvss_v31_vector_string, cvss_v31_exploitability_score, cvss_v31_impact_score
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        str(row['cve_id']),
                        str(row['source_identifier']),
                        str(row['published_date']),
                        str(row['last_modified_date']),
                        str(row['vuln_status']),
                        str(row['description']),
                        row['base_score'] if pd.notnull(row['base_score']) else None,
                        str(row['vector_string']) if pd.notnull(row['vector_string']) else None,
                        str(row['access_vector']) if pd.notnull(row['access_vector']) else None,
                        str(row['access_complexity']) if pd.notnull(row['access_complexity']) else None,
                        str(row['authentication']) if pd.notnull(row['authentication']) else None,
                        str(row['confidentiality_impact']) if pd.notnull(row['confidentiality_impact']) else None,
                        str(row['integrity_impact']) if pd.notnull(row['integrity_impact']) else None,
                        str(row['availability_impact']) if pd.notnull(row['availability_impact']) else None,
                        row['exploitability_score'] if pd.notnull(row['exploitability_score']) else None,
                        row['impact_score'] if pd.notnull(row['impact_score']) else None,
                        row['cvss_v3_base_score'] if pd.notnull(row['cvss_v3_base_score']) else None,
                        str(row['cvss_v3_vector_string']) if pd.notnull(row['cvss_v3_vector_string']) else None,
                        row['cvss_v3_exploitability_score'] if pd.notnull(row['cvss_v3_exploitability_score']) else None,
                        row['cvss_v3_impact_score'] if pd.notnull(row['cvss_v3_impact_score']) else None,
                        row['cvss_v31_base_score'] if pd.notnull(row['cvss_v31_base_score']) else None,
                        str(row['cvss_v31_vector_string']) if pd.notnull(row['cvss_v31_vector_string']) else None,
                        row['cvss_v31_exploitability_score'] if pd.notnull(row['cvss_v31_exploitability_score']) else None,
                        row['cvss_v31_impact_score'] if pd.notnull(row['cvss_v31_impact_score']) else None
                    ))
                    if index % 1000 == 0:
                        logging.info(f"Inserted {index} rows")
                    break
                except pyodbc.OperationalError as e:
                    logging.error(f"Operational error on row {index}: {e}")
                    logging.error(f"Values: {row}")
                    if attempt < retries - 1:
                        logging.info(f"Retrying row {index}, attempt {attempt + 1}")
                        time.sleep(5)  # Wait before retrying
                    else:
                        raise
                except Exception as e:
                    logging.error(f"Error inserting row {index}: {e}")
                    logging.error(f"Values: {row}")
                    break
        conn.commit()
    logging.info(f"All data has been inserted into {table_name} table.")

# Connect to Azure SQL Database with retry logic
def connect_to_sql():
    retries = 3
    for attempt in range(retries):
        try:
            conn = pyodbc.connect('INSERT DB CONNECTION STRING HERE') #Used for importing data in MSSQL DB
            return conn
        except pyodbc.OperationalError as e:
            logging.error(f"Operational error on connection attempt {attempt + 1}: {e}")
            if attempt < retries - 1:
                logging.info(f"Retrying connection, attempt {attempt + 1}")
                time.sleep(5)  # Wait before retrying
            else:
                raise

# Function to save progress to a file
def save_progress(start_index):
    with open('progress_nvd_nist.json', 'w') as f:
        json.dump({'start_index': start_index}, f)

# Function to load progress from a file
def load_progress():
    if os.path.exists('progress_nvd_nist.json'):
        with open('progress_nvd_nist.json', 'r') as f:
            return json.load(f)
    return None

conn = connect_to_sql()

# Create table for NVD data (if it doesn't already exist)
cursor = conn.cursor()
cursor.execute('''
IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='NVD_NIST2' AND xtype='U')
CREATE TABLE NVD_NIST2 (
    cve_id NVARCHAR(50),
    source_identifier NVARCHAR(255),
    published_date DATETIME,
    last_modified_date DATETIME,
    vuln_status NVARCHAR(50),
    description NVARCHAR(MAX),
    base_score FLOAT,
    vector_string NVARCHAR(255),
    access_vector NVARCHAR(50),
    access_complexity NVARCHAR(50),
    authentication NVARCHAR(50),
    confidentiality_impact NVARCHAR(50),
    integrity_impact NVARCHAR(50),
    availability_impact NVARCHAR(50),
    exploitability_score FLOAT,
    impact_score FLOAT,
    cvss_v3_base_score FLOAT,
    cvss_v3_vector_string NVARCHAR(255),
    cvss_v3_exploitability_score FLOAT,
    cvss_v3_impact_score FLOAT,
    cvss_v31_base_score FLOAT,
    cvss_v31_vector_string NVARCHAR(255),
    cvss_v31_exploitability_score FLOAT,
    cvss_v31_impact_score FLOAT
)
''')
conn.commit()

# Fetch and insert data from NVD API
progress = load_progress()
if progress:
    start_index = progress['start_index']
else:
    start_index = 0

total_results = 254724  # Assuming the total number of results

while start_index < total_results:
    logging.info(f"Fetching data starting at index {start_index}")
    json_data = fetch_data_from_nvd(start_index)
    if 'vulnerabilities' not in json_data or not json_data['vulnerabilities']:
        break
    nvd_df = parse_nvd_data(json_data)
    insert_data_to_sql(nvd_df, 'NVD_NIST2', conn)
    save_progress(start_index)
    start_index += 2000

print("All NVD data has been successfully inserted into Azure SQL Database.")
